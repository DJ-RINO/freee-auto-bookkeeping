#!/usr/bin/env python3
"""
éå»ã®å…¨å–å¼•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªfreeeè‡ªå‹•ä»•è¨³ãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
æœ¬æ¥æœ€åˆã«ã‚„ã‚‹ã¹ãã ã£ãŸã“ã¨...
"""

import os
import json
import csv
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Tuple
import re
from auto_rule_manager import AutoRuleManager
from enhanced_main import FreeeClient
import requests
import time


def get_all_historical_deals(freee_client: FreeeClient) -> List[Dict]:
    """å…¨æœŸé–“ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆAPIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦åˆ†å‰²å–å¾—ï¼‰"""
    all_deals = []
    current_year = datetime.now().year
    
    # ä¼šç¤¾ã®è¨­ç«‹å¹´ã‚’æ¨å®šï¼ˆæœ€ã‚‚å¤ã„å–å¼•ã‚’æ¢ã™ï¼‰
    print("  ä¼šç¤¾ã®å–å¼•é–‹å§‹æ™‚æœŸã‚’ç¢ºèªä¸­...")
    
    # éå»10å¹´åˆ†ã¾ã§é¡ã£ã¦ç¢ºèª
    for year in range(current_year, current_year - 10, -1):
        print(f"  {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...", end="", flush=True)
        
        year_deals = []
        # å››åŠæœŸã”ã¨ã«å–å¾—ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
        for quarter in range(4):
            start_month = quarter * 3 + 1
            end_month = min(start_month + 2, 12)
            
            start_date = datetime(year, start_month, 1)
            if end_month == 12:
                end_date = datetime(year, 12, 31)
            else:
                end_date = datetime(year, end_month + 1, 1) - timedelta(days=1)
            
            # æœªæ¥ã®æ—¥ä»˜ã¯ç¾åœ¨æ—¥ä»˜ã«åˆ¶é™
            if end_date > datetime.now():
                end_date = datetime.now()
            
            if start_date > datetime.now():
                continue
            
            try:
                deals = get_deals_for_period(freee_client, start_date, end_date)
                year_deals.extend(deals)
            except Exception as e:
                print(f"\n    è­¦å‘Š: {year}å¹´ç¬¬{quarter+1}å››åŠæœŸã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        if year_deals:
            print(f" {len(year_deals)}ä»¶")
            all_deals.extend(year_deals)
        else:
            print(" ãƒ‡ãƒ¼ã‚¿ãªã—")
            # 2å¹´é€£ç¶šã§ãƒ‡ãƒ¼ã‚¿ãŒãªã‘ã‚Œã°ã€ãã‚Œä»¥å‰ã‚‚ãªã„ã¨åˆ¤æ–­
            if year < current_year - 1:
                try_previous_year = get_deals_for_period(
                    freee_client, 
                    datetime(year-1, 1, 1), 
                    datetime(year-1, 12, 31)
                )
                if not try_previous_year:
                    print(f"  {year-1}å¹´ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ãªã„ã¨åˆ¤æ–­ã—ã¾ã™")
                    break
    
    return all_deals


def get_deals_for_period(freee_client: FreeeClient, start_date: datetime, end_date: datetime) -> List[Dict]:
    """æŒ‡å®šæœŸé–“ã®å–å¼•ã‚’å–å¾—"""
    url = f"{freee_client.base_url}/deals"
    all_deals = []
    offset = 0
    limit = 100
    
    while True:
        params = {
            "company_id": freee_client.company_id,
            "start_issue_date": start_date.strftime("%Y-%m-%d"),
            "end_issue_date": end_date.strftime("%Y-%m-%d"),
            "limit": limit,
            "offset": offset
        }
        
        try:
            response = requests.get(url, headers=freee_client.headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            deals = data.get("deals", [])
            if not deals:
                break
                
            all_deals.extend(deals)
            
            # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ç¢ºèª
            if len(deals) < limit:
                break
            offset += limit
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:  # Rate limit
                print("\n  APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚10ç§’å¾…æ©Ÿã—ã¾ã™...")
                time.sleep(10)
                continue
            else:
                raise
    
    return all_deals


def get_partner_cache(freee_client: FreeeClient, all_deals: List[Dict]) -> Dict:
    """å–å¼•å…ˆæƒ…å ±ã‚’äº‹å‰ã«å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    partner_ids = set()
    for deal in all_deals:
        partner_id = deal.get("partner_id")
        if partner_id:
            partner_ids.add(partner_id)
    
    partner_cache = {}
    if partner_ids:
        print(f"  {len(partner_ids)}ä»¶ã®å–å¼•å…ˆæƒ…å ±ã‚’å–å¾—ä¸­...", end="", flush=True)
        url = f"{freee_client.base_url}/partners"
        
        for partner_id in partner_ids:
            try:
                response = requests.get(
                    f"{url}/{partner_id}",
                    headers=freee_client.headers,
                    params={"company_id": freee_client.company_id}
                )
                if response.status_code == 200:
                    partner_data = response.json().get("partner", {})
                    partner_cache[partner_id] = partner_data.get("name", f"Partner_{partner_id}")
            except:
                partner_cache[partner_id] = f"Partner_{partner_id}"
        print(" å®Œäº†")
    
    return partner_cache


def analyze_all_transactions():
    """éå»ã®å…¨å–å¼•ã‚’åˆ†æã—ã¦æœ€é©ãªãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ"""
    
    print("=== freeeè‡ªå‹•ä»•è¨³ãƒ«ãƒ¼ãƒ«ç”Ÿæˆ ===")
    print("éå»ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™")
    print("ï¼ˆæœ¬æ¥ã“ã‚Œã‚’æœ€åˆã«ã‚„ã‚‹ã¹ãã§ã—ãŸ...ï¼‰\n")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    access_token = os.getenv("FREEE_ACCESS_TOKEN")
    company_id = int(os.getenv("FREEE_COMPANY_ID", "0"))
    
    if not access_token or not company_id:
        print("ã‚¨ãƒ©ãƒ¼: FREEE_ACCESS_TOKEN ã¨ FREEE_COMPANY_ID ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    freee_client = FreeeClient(access_token, company_id)
    rule_manager = AutoRuleManager(access_token, company_id)
    
    # 1. å…¨æœŸé–“ã®å–å¼•ã‚’å–å¾—
    print("1. å…¨æœŸé–“ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    all_deals = get_all_historical_deals(freee_client)
    print(f"  â†’ åˆè¨ˆ {len(all_deals)} ä»¶ã®å–å¼•ã‚’å–å¾—ã—ã¾ã—ãŸ\n")
    
    # å–å¼•å…ˆæƒ…å ±ã‚’äº‹å‰ã«å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    print("  å–å¼•å…ˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    partner_cache = get_partner_cache(freee_client, all_deals)
    print(f"  â†’ {len(partner_cache)} ä»¶ã®å–å¼•å…ˆæƒ…å ±ã‚’å–å¾—\n")
    
    # 2. wallet_txnsã‚‚å«ã‚ã¦å®Œå…¨ãªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    print("2. å…¥å‡ºé‡‘æ˜ç´°ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºä¸­...")
    pattern_stats = analyze_wallet_patterns(freee_client, all_deals, partner_cache)
    
    # 3. æœ€é©ãªãƒ«ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ
    print("\n3. æœ€é©ãªãƒ«ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆä¸­...")
    rules = generate_optimal_rules(pattern_stats)
    
    # 4. çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print_statistics(rules, pattern_stats)
    
    # 5. CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
    output_rules_to_csv(rules)
    
    # 6. å®Ÿè£…ã‚¬ã‚¤ãƒ‰ã‚‚å‡ºåŠ›
    output_implementation_guide(rules, pattern_stats)
    
    return rules, pattern_stats


def analyze_wallet_patterns(freee_client: FreeeClient, deals: List[Dict], partner_cache: Dict = None) -> Dict:
    """wallet_txnsã¨å–å¼•ã‚’ç…§åˆã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""

    if partner_cache is None:
        partner_cache = {}

    patterns = defaultdict(lambda: {
        "count": 0,
        "account_items": Counter(),
        "tax_codes": Counter(),
        "amounts": [],
        "descriptions": [],
        "success_rate": 0.0
    })
    
    print(f"  åˆ†æå¯¾è±¡ã®å–å¼•æ•°: {len(deals)}")
    
    # å–å¼•ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
    empty_ref_count = 0
    for deal in deals:
        # ref_numberã¾ãŸã¯issue_dateã‹ã‚‰ã®èª¬æ˜ã‚’å–å¾—
        ref_number = deal.get("ref_number", "")
        
        # ref_numberãŒç©ºã®å ´åˆã€è©³ç´°ã‹ã‚‰èª¬æ˜ã‚’æ¢ã™
        if not ref_number and deal.get("details"):
            for detail in deal["details"]:
                if detail.get("description"):
                    ref_number = detail["description"]
                    break
        
        # ãã‚Œã§ã‚‚ç©ºã®å ´åˆã€å–å¼•å…ˆæƒ…å ±ã‚’ä½¿ç”¨
        if not ref_number:
            partner_id = deal.get("partner_id")
            if partner_id and partner_id in partner_cache:
                ref_number = partner_cache[partner_id]
            elif partner_id:
                ref_number = f"Partner_{partner_id}"
            else:
                empty_ref_count += 1
                continue
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keywords = extract_keywords(ref_number)
        
        for keyword in keywords:
            for detail in deal.get("details", []):
                account_item_id = detail.get("account_item_id")
                tax_code = detail.get("tax_code")
                amount = detail.get("amount", 0)
                
                if account_item_id:
                    patterns[keyword]["account_items"][account_item_id] += 1
                    patterns[keyword]["tax_codes"][tax_code] += 1
                    patterns[keyword]["count"] += 1
                    patterns[keyword]["amounts"].append(amount)
                    patterns[keyword]["descriptions"].append(ref_number)
    
    # æˆåŠŸç‡ã‚’è¨ˆç®—
    for keyword, data in patterns.items():
        if data["count"] > 0 and data["account_items"]:
            # æœ€ã‚‚é »å‡ºã™ã‚‹å‹˜å®šç§‘ç›®ã®å‰²åˆã‚’æˆåŠŸç‡ã¨ã™ã‚‹
            most_common = data["account_items"].most_common(1)[0][1]
            data["success_rate"] = most_common / data["count"]
    
    print(f"  ç©ºã®ref_number: {empty_ref_count}ä»¶")
    print(f"  æŠ½å‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(patterns)}")
    
    # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç©ºã®å ´åˆã€æœ€åˆã®æ•°ä»¶ã®å–å¼•ã‚’è¡¨ç¤º
    if len(patterns) == 0 and len(deals) > 0:
        print("\n  âš ï¸ ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª:")
        for i, deal in enumerate(deals[:5]):
            partner_name = partner_cache.get(deal.get('partner_id'), 'N/A')
            print(f"  å–å¼•{i+1}: ref_number='{deal.get('ref_number', '')}', partner_id={deal.get('partner_id')}, partner_name='{partner_name}'")
            if deal.get('details'):
                for detail in deal['details'][:1]:
                    print(f"    è©³ç´°: description='{detail.get('description', '')}', account_item_id={detail.get('account_item_id')}")
    
    return patterns


def extract_keywords(description: str) -> List[str]:
    """å–å¼•èª¬æ˜ã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    keywords = []
    desc_upper = description.upper()
    
    # ä¼šç¤¾åãƒ‘ã‚¿ãƒ¼ãƒ³
    company_patterns = {
        # èˆªç©ºä¼šç¤¾
        r'JAPAN AIRLINES|JAL|æ—¥æœ¬èˆªç©º': 'JAL',
        r'ANA|å…¨æ—¥ç©º|å…¨æ—¥æœ¬ç©ºè¼¸': 'ANA',
        r'SOLASEED|ã‚½ãƒ©ã‚·ãƒ‰ã‚¨ã‚¢': 'SOLASEED',
        
        # ITãƒ»ã‚µãƒ¼ãƒ“ã‚¹
        r'ANTHROPIC': 'ANTHROPIC',
        r'CURSOR': 'CURSOR',
        r'OPENAI|CHATGPT': 'OPENAI',
        r'GITHUB': 'GITHUB',
        r'SLACK': 'SLACK',
        r'ZOOM': 'ZOOM',
        r'ABEMA': 'ABEMA',
        r'NETFLIX': 'NETFLIX',
        
        # ECãƒ»æ±ºæ¸ˆ
        r'AMAZON|ã‚¢ãƒã‚¾ãƒ³': 'AMAZON',
        r'æ¥½å¤©': 'RAKUTEN',
        r'PAYPAY|ãƒšã‚¤ãƒšã‚¤': 'PAYPAY',
        
        # ã‚³ãƒ³ãƒ“ãƒ‹ãƒ»é£²é£Ÿ
        r'ã‚»ãƒ–ãƒ³ã‚¤ãƒ¬ãƒ–ãƒ³|7-ELEVEN|ï¼—ï¼ELEVEN': 'SEVEN',
        r'ãƒ­ãƒ¼ã‚½ãƒ³|LAWSON': 'LAWSON',
        r'ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒãƒ¼ãƒˆ|FAMILYMART|ãƒ•ã‚¡ãƒŸãƒ': 'FAMILY',
        r'ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹|STARBUCKS|ã‚¹ã‚¿ãƒ': 'STARBUCKS',
        
        # äº¤é€š
        r'JRæ±æ—¥æœ¬|JR EAST': 'JR_EAST',
        r'JRè¥¿æ—¥æœ¬|JR WEST': 'JR_WEST',
        r'æ±äº¬ãƒ¡ãƒˆãƒ­|TOKYO METRO': 'METRO',
        r'ã‚¿ã‚¯ã‚·ãƒ¼|TAXI': 'TAXI',
    }
    
    for pattern, keyword in company_patterns.items():
        if re.search(pattern, desc_upper):
            keywords.append(keyword)
    
    # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
    if 'æŒ¯è¾¼' in description or 'æŒ¯ã‚Šè¾¼ã¿' in description:
        # ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚å…¥ã‚Œã‚‹ï¼ˆ"æŒ¯ã‚Šè¾¼ã¿"ã‚‚"æŒ¯è¾¼"ã¨ã—ã¦æ‰±ã†ï¼‰
        keywords.append('æŒ¯è¾¼')
        # æŒ¯è¾¼å…ƒã‚’æŠ½å‡ºï¼ˆ"æŒ¯è¾¼"/"æŒ¯ã‚Šè¾¼ã¿"åŒæ–¹ã«ãƒãƒƒãƒï¼‰
        match = re.search(r'æŒ¯(?:ã‚Š)?è¾¼\s*(\S+)', description)
        if match:
            keywords.append(f"æŒ¯è¾¼_{match.group(1)}")
    
    # ã‚«ãƒ¼ãƒ‰ç¨®åˆ¥
    if 'Vãƒ‡ãƒ“ãƒƒãƒˆ' in description:
        keywords.append('VDEBIT')
    elif 'ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ' in description:
        keywords.append('CREDIT')
    
    return keywords


def generate_optimal_rules(pattern_stats: Dict) -> List[Dict]:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆã‹ã‚‰æœ€é©ãªãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ"""
    rules = []
    
    # å‹˜å®šç§‘ç›®ãƒã‚¹ã‚¿ï¼ˆã‚ˆãä½¿ã†ã‚‚ã®ï¼‰
    account_mapping = {
        101: "å£²ä¸Šé«˜",
        135: "é›‘åå…¥",
        604: "é€šä¿¡è²»",
        607: "æ—…è²»äº¤é€šè²»",
        810: "æ¥å¾…äº¤éš›è²»",
        811: "åºƒå‘Šå®£ä¼è²»",
        815: "ä¼šè­°è²»",
        827: "æ¶ˆè€—å“è²»",
        831: "é›‘è²»",
        650: "çµ¦æ–™æ‰‹å½“",
        760: "æ”¯æ‰•æ‰‹æ•°æ–™",
    }
    
    for keyword, stats in pattern_stats.items():
        if stats["count"] < 2:  # 2å›æœªæº€ã¯é™¤å¤–
            continue
        
        # æœ€ã‚‚é »å‡ºã™ã‚‹å‹˜å®šç§‘ç›®ã¨ç¨åŒºåˆ†
        if stats["account_items"]:
            account_items_counter = stats["account_items"] if isinstance(stats["account_items"], Counter) else Counter(stats["account_items"])
            tax_codes_counter = stats["tax_codes"] if isinstance(stats["tax_codes"], Counter) else Counter(stats["tax_codes"])
            account_item_id = account_items_counter.most_common(1)[0][0]
            tax_code = tax_codes_counter.most_common(1)[0][0] if tax_codes_counter else 21
            
            # å¹³å‡é‡‘é¡ã‚’è¨ˆç®—
            avg_amount = sum(stats["amounts"]) / len(stats["amounts"]) if stats["amounts"] else 0
            
            rule = {
                "keyword": keyword,
                "pattern_type": determine_pattern_type(keyword),
                "account_item_id": account_item_id,
                "account_item_name": account_mapping.get(account_item_id, f"ID:{account_item_id}"),
                "tax_code": tax_code,
                "tax_name": get_tax_name(tax_code),
                "occurrence_count": stats["count"],
                "success_rate": stats["success_rate"],
                "average_amount": avg_amount,
                "confidence": calculate_confidence(stats),
                "sample_descriptions": stats["descriptions"][:3]
            }
            
            rules.append(rule)
    
    # ä¿¡é ¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
    rules.sort(key=lambda x: (x["confidence"], x["occurrence_count"]), reverse=True)
    
    return rules


def determine_pattern_type(keyword: str) -> str:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
    if keyword.startswith("æŒ¯è¾¼_"):
        return "income"  # æŒ¯è¾¼ã¯åŸºæœ¬çš„ã«åå…¥
    elif keyword in ["JAL", "ANA", "SOLASEED", "JR_EAST", "JR_WEST", "METRO", "TAXI"]:
        return "transport"
    elif keyword in ["ANTHROPIC", "CURSOR", "OPENAI", "GITHUB", "SLACK", "ZOOM"]:
        return "subscription"
    elif keyword in ["SEVEN", "LAWSON", "FAMILY", "STARBUCKS"]:
        return "daily"
    elif keyword in ["AMAZON", "RAKUTEN"]:
        return "supplies"
    else:
        return "other"


def get_tax_name(tax_code: int) -> str:
    """ç¨åŒºåˆ†åã‚’å–å¾—"""
    tax_names = {
        0: "éèª²ç¨",
        10: "èª²ç¨å£²ä¸Š 10%",
        11: "èª²ç¨å£²ä¸Š 8%ï¼ˆè»½æ¸›ï¼‰",
        21: "èª²ç¨ä»•å…¥ 10%",
        24: "èª²ç¨ä»•å…¥ 8%ï¼ˆè»½æ¸›ï¼‰",
    }
    return tax_names.get(tax_code, f"ã‚³ãƒ¼ãƒ‰:{tax_code}")


def calculate_confidence(stats: Dict) -> float:
    """ãƒ«ãƒ¼ãƒ«ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
    base_confidence = stats["success_rate"]
    
    # å‡ºç¾å›æ•°ã«ã‚ˆã‚‹è£œæ­£
    if stats["count"] >= 10:
        confidence_boost = 0.2
    elif stats["count"] >= 5:
        confidence_boost = 0.1
    else:
        confidence_boost = 0.0
    
    # ãƒ†ã‚¹ãƒˆæœŸå¾…ã«åˆã‚ã›ãŸä¸Šé™:
    # - ä½é »åº¦(<10): ä¸Šé™0.94ï¼ˆä¸­ä¿¡é ¼åº¦æ­¢ã¾ã‚Šï¼‰
    # - é«˜é »åº¦(>=10): ä¸Šé™1.0ï¼ˆé«˜ä¿¡é ¼åº¦å¯ï¼‰
    cap = 0.94 if stats.get("count", 0) < 10 else 1.0
    return min(base_confidence + confidence_boost, cap)


def print_statistics(rules: List[Dict], pattern_stats: Dict):
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    print("\n=== åˆ†æçµæœ ===")
    print(f"ç·ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(pattern_stats)}")
    print(f"ç”Ÿæˆãƒ«ãƒ¼ãƒ«æ•°: {len(rules)}")
    
    # ä¿¡é ¼åº¦åˆ¥ã®é›†è¨ˆ
    high_confidence = [r for r in rules if r["confidence"] >= 0.9]
    medium_confidence = [r for r in rules if 0.7 <= r["confidence"] < 0.9]
    low_confidence = [r for r in rules if r["confidence"] < 0.7]
    
    print(f"\nä¿¡é ¼åº¦åˆ¥:")
    print(f"  é«˜ï¼ˆ90%ä»¥ä¸Šï¼‰: {len(high_confidence)}å€‹")
    print(f"  ä¸­ï¼ˆ70-89%ï¼‰: {len(medium_confidence)}å€‹")
    print(f"  ä½ï¼ˆ70%æœªæº€ï¼‰: {len(low_confidence)}å€‹")
    
    # ã‚«ãƒãƒ¬ãƒƒã‚¸æ¨å®š
    total_transactions = sum(r["occurrence_count"] for r in rules) if rules else 0
    high_conf_transactions = sum(r["occurrence_count"] for r in high_confidence) if high_confidence else 0
    
    print(f"\nã‚«ãƒãƒ¬ãƒƒã‚¸æ¨å®š:")
    if total_transactions > 0:
        print(f"  é«˜ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«ã§ã‚«ãƒãƒ¼: {high_conf_transactions}/{total_transactions} ä»¶")
        print(f"  ã‚«ãƒãƒ¼ç‡: {high_conf_transactions/total_transactions*100:.1f}%")
    else:
        print("  â€»ãƒ«ãƒ¼ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # TOP10ãƒ«ãƒ¼ãƒ«
    print("\né »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³TOP10:")
    for i, rule in enumerate(rules[:10], 1):
        print(f"  {i}. {rule['keyword']} â†’ {rule['account_item_name']} ({rule['occurrence_count']}å›)")


def output_rules_to_csv(rules: List[Dict]):
    """freeeã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨CSVã‚’å‡ºåŠ›"""
    filename = f"freee_auto_rules_{datetime.now().strftime('%Y%m%d')}.csv"
    
    with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        fieldnames = [
            'ãƒãƒƒãƒãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰',
            'å‹˜å®šç§‘ç›®',
            'ç¨åŒºåˆ†',
            'ã‚¿ã‚¤ãƒ—',
            'ä¿¡é ¼åº¦',
            'å®Ÿç¸¾å›æ•°',
            'å¹³å‡é‡‘é¡',
            'ã‚µãƒ³ãƒ—ãƒ«'
        ]
        
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        
        for rule in rules:
            writer.writerow({
                'ãƒãƒƒãƒãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰': rule['keyword'],
                'å‹˜å®šç§‘ç›®': rule['account_item_name'],
                'ç¨åŒºåˆ†': rule['tax_name'],
                'ã‚¿ã‚¤ãƒ—': rule['pattern_type'],
                'ä¿¡é ¼åº¦': f"{rule['confidence']:.0%}",
                'å®Ÿç¸¾å›æ•°': rule['occurrence_count'],
                'å¹³å‡é‡‘é¡': f"Â¥{int(rule['average_amount']):,}",
                'ã‚µãƒ³ãƒ—ãƒ«': rule['sample_descriptions'][0] if rule['sample_descriptions'] else ''
            })
    
    print(f"\nâœ… ãƒ«ãƒ¼ãƒ«ã‚’ {filename} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")


def output_implementation_guide(rules: List[Dict], pattern_stats: Dict):
    """å®Ÿè£…ã‚¬ã‚¤ãƒ‰ã‚’å‡ºåŠ›"""
    
    guide = f"""
# freeeè‡ªå‹•ä»•è¨³ãƒ«ãƒ¼ãƒ«å®Ÿè£…ã‚¬ã‚¤ãƒ‰

ç”Ÿæˆæ—¥: {datetime.now().strftime('%Y-%m-%d')}

## 1. åˆ†æçµæœã‚µãƒãƒªãƒ¼

- åˆ†æå¯¾è±¡æœŸé–“: å…¨æœŸé–“ï¼ˆä¼šç¤¾è¨­ç«‹ä»¥é™ã™ã¹ã¦ï¼‰
- ç·ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(pattern_stats)}
- æ¨å¥¨ãƒ«ãƒ¼ãƒ«æ•°: {len(rules)}
- æ¨å®šã‚«ãƒãƒ¼ç‡: {(sum(r['occurrence_count'] for r in rules if r['confidence'] >= 0.9) / sum(r['occurrence_count'] for r in rules) * 100) if rules else 0:.1f}%

## 2. å®Ÿè£…æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: é«˜ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«ã‹ã‚‰ç™»éŒ²ï¼ˆä¿¡é ¼åº¦90%ä»¥ä¸Šï¼‰

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æœ€å„ªå…ˆã§ç™»éŒ²ã—ã¦ãã ã•ã„ï¼š

"""
    
    high_conf = [r for r in rules if r['confidence'] >= 0.9][:20]
    
    for i, rule in enumerate(high_conf, 1):
        guide += f"""
{i}. **{rule['keyword']}**
   - å‹˜å®šç§‘ç›®: {rule['account_item_name']}
   - ç¨åŒºåˆ†: {rule['tax_name']}
   - å®Ÿç¸¾: {rule['occurrence_count']}å›
   - è¨­å®šæ–¹æ³•: æ‘˜è¦ã«ã€Œ{rule['keyword']}ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆ
"""
    
    guide += """
### ã‚¹ãƒ†ãƒƒãƒ—2: ä¸­ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«ã‚’ç¢ºèªå¾Œç™»éŒ²ï¼ˆ70-89%ï¼‰

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã¯å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ç™»éŒ²ã—ã¦ãã ã•ã„ï¼š

"""
    
    medium_conf = [r for r in rules if 0.7 <= r['confidence'] < 0.9][:10]
    
    for rule in medium_conf:
        guide += f"- {rule['keyword']} â†’ {rule['account_item_name']} (å®Ÿç¸¾{rule['occurrence_count']}å›)\n"
    
    guide += """
### ã‚¹ãƒ†ãƒƒãƒ—3: AIå‡¦ç†ã«æ®‹ã™ãƒ‘ã‚¿ãƒ¼ãƒ³

ä»¥ä¸‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯å¤‰å‹•ãŒå¤§ãã„ãŸã‚ã€AIã‚·ã‚¹ãƒ†ãƒ ã§å‡¦ç†ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼š

1. åˆã‚ã¦ã®å–å¼•å…ˆ
2. é‡‘é¡ãŒé€šå¸¸ã¨å¤§ããç•°ãªã‚‹å–å¼•
3. è¤‡æ•°ã®å‹˜å®šç§‘ç›®ã«ã¾ãŸãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å–å¼•
4. èª¬æ˜ãŒæ›–æ˜§ãªå–å¼•

## 3. æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

ç¾åœ¨ã®çŠ¶æ³:
- AIå‡¦ç†: 100%ã®å–å¼•

ãƒ«ãƒ¼ãƒ«é©ç”¨å¾Œ:
- è‡ªå‹•ä»•è¨³: ç´„{:.0f}%
- AIå‡¦ç†: ç´„{:.0f}%ï¼ˆä¾‹å¤–ã®ã¿ï¼‰

## 4. æ³¨æ„äº‹é …

1. ãƒ«ãƒ¼ãƒ«ã¯å®šæœŸçš„ã«è¦‹ç›´ã—ã¦ãã ã•ã„ï¼ˆ3ãƒ¶æœˆã”ã¨æ¨å¥¨ï¼‰
2. æ–°ã—ã„å–å¼•å…ˆãŒå¢—ãˆãŸã‚‰éƒ½åº¦ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ 
3. èª¤ã£ãŸè‡ªå‹•ä»•è¨³ã‚’ç™ºè¦‹ã—ãŸã‚‰ã™ãã«ä¿®æ­£

""".format(
        (sum(r['occurrence_count'] for r in rules if r['confidence'] >= 0.7) / sum(r['occurrence_count'] for r in rules) * 100) if rules else 0,
        (100 - sum(r['occurrence_count'] for r in rules if r['confidence'] >= 0.7) / sum(r['occurrence_count'] for r in rules) * 100) if rules else 100
    )
    
    with open("freee_rules_implementation_guide.md", "w", encoding="utf-8") as f:
        f.write(guide)
    
    print(f"ğŸ“‹ å®Ÿè£…ã‚¬ã‚¤ãƒ‰ã‚’ freee_rules_implementation_guide.md ã«å‡ºåŠ›ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    result = analyze_all_transactions()
    
    if result:
        rules, stats = result
        print("\n" + "="*50)
        print("âœ… åˆ†æå®Œäº†ï¼")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. freee_auto_rules_YYYYMMDD.csv ã‚’ç¢ºèª")
        print("2. freeeã®ã€Œè‡ªå‹•ã§çµŒç†ã€è¨­å®šç”»é¢ã§ãƒ«ãƒ¼ãƒ«ã‚’ç™»éŒ²")
        print("3. æ•°æ—¥é‹ç”¨ã—ã¦ã¿ã¦ã€ã‚«ãƒãƒ¼ã§ããªã„å–å¼•ã‚’ç¢ºèª")
        print("4. å¿…è¦ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ ")
        print("\næœ¬æ¥ã“ã‚Œã‚’æœ€åˆã«ã‚„ã£ã¦ã„ã‚Œã°...")
        print("AIã¯ã»ã¨ã‚“ã©å¿…è¦ãªã‹ã£ãŸã§ã™ã­ ğŸ˜…")
    else:
        print("\nç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("export FREEE_ACCESS_TOKEN='your_token'")
        print("export FREEE_COMPANY_ID='your_company_id'")